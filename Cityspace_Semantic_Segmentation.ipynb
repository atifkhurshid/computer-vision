{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cityspace Semantic Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJTdLfgqJXgv"
      },
      "source": [
        "! unzip -q A3_Dataset.zip\n",
        "! rm A3_Dataset.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gEzrFjiJO7K"
      },
      "source": [
        "Preparing dataset folder structure for ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLD-pm21aeN1"
      },
      "source": [
        "! mkdir dataset\n",
        "! mkdir dataset/train\n",
        "! mkdir dataset/train/images dataset/train/masks\n",
        "! mkdir dataset/test\n",
        "! mkdir dataset/test/images dataset/test/masks\n",
        "\n",
        "! mv A3_Dataset/dataset1/images_prepped_train dataset/train/images\n",
        "! mv A3_Dataset/dataset1/images_prepped_test dataset/test/images\n",
        "! mv A3_Dataset/dataset1/annotations_prepped_train dataset/train/masks\n",
        "! mv A3_Dataset/dataset1/annotations_prepped_test dataset/test/masks\n",
        "\n",
        "! rm -r A3_Dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58w_UtvJfL1q"
      },
      "source": [
        "Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mhZfogcuiDB"
      },
      "source": [
        "! pip install -U segmentation-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPj6Ptqpm_UI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVE9aoTfAvu"
      },
      "source": [
        "Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLnF5wYpovTZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "\n",
        "\n",
        "def show(image):\n",
        "    io.imshow(image.astype(np.uint8))\n",
        "    plt.show()\n",
        "\n",
        "def segshow(mask):\n",
        "    seg = color.label2rgb(mask, bg_label=0)\n",
        "    show(seg)\n",
        "\n",
        "def combinedshow(image, mask_true, mask_pred=None, figsize=(15,3)):\n",
        "    image = image.astype(np.uint8)\n",
        "    mask_true = np.argmax(mask_true, 2)\n",
        "    if mask_pred is not None:\n",
        "        mask_pred = np.argmax(mask_pred, 2)\n",
        "\n",
        "    cols = 5 if mask_pred is not None else 3\n",
        "    fig, ax = plt.subplots(1, cols, figsize=figsize)\n",
        "\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].axis('off')\n",
        "    ax[0].imshow(image)\n",
        "\n",
        "    ax[1].set_title('Ground Truth')\n",
        "    ax[1].axis('off')\n",
        "    ax[1].imshow(color.label2rgb(mask_true, bg_label=0))\n",
        "\n",
        "    ax[2].set_title('Original + Ground Truth')\n",
        "    ax[2].axis('off')\n",
        "    ax[2].imshow(color.label2rgb(mask_true, image, alpha=0.3, bg_label=0))\n",
        "\n",
        "    if mask_pred is not None:\n",
        "        ax[3].set_title('Predicted Mask')\n",
        "        ax[3].axis('off')\n",
        "        ax[3].imshow(color.label2rgb(mask_pred, bg_label=0))\n",
        "\n",
        "        ax[4].set_title('Original + Predicted Mask')\n",
        "        ax[4].axis('off')\n",
        "        ax[4].imshow(color.label2rgb(mask_pred, image, alpha=0.3, bg_label=0))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nnY5QFbfPM4"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DARNFBVl-vZ"
      },
      "source": [
        "DATASET_DIR = 'dataset/'\n",
        "\n",
        "TRAIN_X = DATASET_DIR + 'train/images/'\n",
        "TRAIN_Y = DATASET_DIR + 'train/masks/'\n",
        "\n",
        "TEST_X = DATASET_DIR + 'test/images/'\n",
        "TEST_Y = DATASET_DIR + 'test/masks/'\n",
        "\n",
        "INPUT_SHAPE = (352, 480)\n",
        "NUM_CLASSES = 12\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OQw_yUMzncz"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import RandomFlip, RandomCrop, RandomRotation, RandomTranslation, RandomZoom\n",
        "\n",
        "\n",
        "def load_data(image_dir, mask_dir, num_classes, input_shape, batch_size, train=False):\n",
        "\n",
        "    def images_masks_generator(images, masks):\n",
        "        images_masks = zip(images, masks)\n",
        "        for (imgs, msks) in images_masks:\n",
        "            rng = np.random.default_rng()\n",
        "\n",
        "            if train:\n",
        "                seed = rng.integers(0, 10000)\n",
        "                imgs = RandomFlip(\n",
        "                    'horizontal', seed=seed)(imgs).numpy()\n",
        "                msks = RandomFlip(\n",
        "                    'horizontal', seed=seed)(msks).numpy()\n",
        "\n",
        "                seed = rng.integers(0, 10000)\n",
        "                imgs = RandomCrop(\n",
        "                    imgs.shape[1], imgs.shape[2], seed=seed)(imgs).numpy()\n",
        "                msks = RandomCrop(\n",
        "                    imgs.shape[1], imgs.shape[2], seed=seed)(msks).numpy()\n",
        "\n",
        "                seed = rng.integers(0, 10000)\n",
        "                imgs = RandomZoom(\n",
        "                    0.2, fill_mode='reflect', seed=seed)(imgs).numpy()\n",
        "                msks = RandomZoom(\n",
        "                    0.2, fill_mode='reflect', seed=seed)(msks).numpy()\n",
        "\n",
        "                seed = rng.integers(0, 10000)\n",
        "                imgs = RandomRotation(\n",
        "                    0.05, fill_mode='reflect', seed=seed)(imgs).numpy()\n",
        "                msks = RandomRotation(\n",
        "                    0.05, fill_mode='reflect', seed=seed)(msks).numpy()\n",
        "\n",
        "            msks = to_categorical(msks, num_classes=num_classes)\n",
        "\n",
        "            yield (imgs, msks)\n",
        "\n",
        "    seed = 42\n",
        "    validation_split = 0.2 if train else 0.0\n",
        "    subset = 'training' if train else None\n",
        "    shuffle = True if train else False\n",
        "\n",
        "    image_data_generator = ImageDataGenerator(\n",
        "        validation_split = validation_split)\n",
        "    \n",
        "    mask_data_generator = ImageDataGenerator(\n",
        "        validation_split = validation_split)\n",
        "    \n",
        "    images = image_data_generator.flow_from_directory(\n",
        "        image_dir,\n",
        "        target_size = input_shape,\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        subset = subset,\n",
        "        shuffle = shuffle,\n",
        "        seed = seed,\n",
        "    )\n",
        "    masks = mask_data_generator.flow_from_directory(\n",
        "        mask_dir,\n",
        "        target_size = input_shape,\n",
        "        color_mode = 'grayscale',\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        subset = subset,\n",
        "        shuffle = shuffle,\n",
        "        seed = seed,\n",
        "    )\n",
        "\n",
        "    if train:\n",
        "        val_images = image_data_generator.flow_from_directory(\n",
        "            image_dir,\n",
        "            target_size = input_shape,\n",
        "            class_mode = None,\n",
        "            batch_size = batch_size,\n",
        "            subset = 'validation',\n",
        "            shuffle = shuffle,\n",
        "            seed = seed,\n",
        "        )\n",
        "        val_masks = mask_data_generator.flow_from_directory(\n",
        "            mask_dir,\n",
        "            target_size = input_shape,\n",
        "            color_mode = 'grayscale',\n",
        "            class_mode = None,\n",
        "            batch_size = batch_size,\n",
        "            subset = 'validation',\n",
        "            shuffle = shuffle,\n",
        "            seed = seed,\n",
        "        )\n",
        "\n",
        "        return images_masks_generator(images, masks), images_masks_generator(val_images, val_masks)\n",
        "    \n",
        "    return images_masks_generator(images, masks)\n",
        "\n",
        "\n",
        "train_data, val_data = load_data(TRAIN_X, TRAIN_Y, NUM_CLASSES, INPUT_SHAPE, BATCH_SIZE, train=True)\n",
        "test_data = load_data(TEST_X, TEST_Y, NUM_CLASSES, INPUT_SHAPE, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxIbsZrJ6jCm"
      },
      "source": [
        "idx = 0\n",
        "images, masks = next(val_data)\n",
        "combinedshow(images[idx], masks[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj_DtDOUeUsU"
      },
      "source": [
        "Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCFvTpQ4mWXp"
      },
      "source": [
        "import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "\"\"\"\n",
        "BACKBONE = 'vgg16'\n",
        "optim = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\"\"\"\n",
        "BACKBONE = 'resnet50'\n",
        "optim = Adam(learning_rate=0.001)\n",
        "\n",
        "\n",
        "def get_model(input_shape, n_classes, backbone):\n",
        "    input = Input(shape=input_shape)\n",
        "    preprocessing = sm.get_preprocessing(backbone)\n",
        "    base_model = sm.Unet(\n",
        "        backbone_name=backbone,\n",
        "        input_shape=input_shape,\n",
        "        classes=n_classes,\n",
        "        activation='softmax',\n",
        "        encoder_weights='imagenet',\n",
        "        decoder_block_type='upsampling')\n",
        "    base_model.layers.pop(0)\n",
        "\n",
        "    inputs = input\n",
        "    x = preprocessing(inputs)\n",
        "    outputs = base_model(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = get_model(INPUT_SHAPE + (3,), NUM_CLASSES, BACKBONE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5yCLR3TeeLd"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hqJMIa7ec-r"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optim,\n",
        "    loss=sm.losses.categorical_focal_dice_loss,\n",
        "    metrics=['accuracy',\n",
        "             sm.metrics.iou_score,\n",
        "             sm.metrics.f1_score,\n",
        "             sm.metrics.precision,\n",
        "             sm.metrics.recall],\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(\n",
        "        factor=0.1, min_delta=0.01, min_lr=0.00001, patience=5, verbose=1),\n",
        "    EarlyStopping(\n",
        "        min_delta=0.001, patience=10, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "H = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=np.ceil(294 / BATCH_SIZE),\n",
        "    validation_steps=np.ceil(73 / BATCH_SIZE),\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK8iQpeaeR2o"
      },
      "source": [
        "Training Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhy4cgD7rZln"
      },
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Categorical Focal Loss + Jaccard Loss\")\n",
        "plt.plot(H.history[\"loss\"], label=\"Training\")\n",
        "plt.plot(H.history[\"val_loss\"], label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(H.history[\"accuracy\"], label=\"Training\")\n",
        "plt.plot(H.history[\"val_accuracy\"], label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Jaccard Score\")\n",
        "plt.plot(H.history[\"iou_score\"], label=\"Training\")\n",
        "plt.plot(H.history[\"val_iou_score\"], label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Dice Score\")\n",
        "plt.plot(H.history[\"f1-score\"], label=\"Training\")\n",
        "plt.plot(H.history[\"val_iou_score\"], label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0llwr7bePc0"
      },
      "source": [
        "Quantitative Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5IgLFlzWTG5"
      },
      "source": [
        "scores = model.evaluate(\n",
        "    test_data,\n",
        "    steps = np.ceil(101 / BATCH_SIZE),\n",
        "    return_dict = True,\n",
        ")\n",
        "\n",
        "print('Jaccard Score: {:.2f}'.format(scores['iou_score']))\n",
        "print('Dice Score: {:.2f}'.format(scores['f1-score']))\n",
        "print('Accuracy: {:.2f}'.format(scores['accuracy']))\n",
        "print('Precision: {:.2f}'.format(scores['precision']))\n",
        "print('Recall: {:.2f}'.format(scores['recall']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnijGxF4eLuF"
      },
      "source": [
        "Qualitative Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXv4oWEGMxJZ"
      },
      "source": [
        "for i in range(4):\n",
        "    images, masks = next(test_data)\n",
        "    image, mask = images[-1], masks[-1]\n",
        "    pred = model(np.array([image]))[0]\n",
        "    combinedshow(image, mask, pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}